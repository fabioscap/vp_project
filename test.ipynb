{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mount drive (colab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\")\n",
    "\n",
    "%cd /content/drive/MyDrive/visiope\n",
    "!rm -rf vp_project\n",
    "!git clone https://github.com/fabioscap/vp_project\n",
    "%cd vp_project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load The Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import torch\n",
    "from torch.utils.data import DataLoader,random_split\n",
    "import torchvision\n",
    "import model\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "torch.manual_seed(2806)\n",
    "\n",
    "p = 0.05\n",
    "depth_sampling = lambda x: utils.sample_depth_random(x,p)\n",
    "\n",
    "depth_transform = torchvision.transforms.Lambda(depth_sampling)\n",
    "data = utils.NYUDepthV2(\"../NYUDepthv2\", \n",
    "                        shape=(240,320),\n",
    "                        depth_transform=depth_transform,\n",
    "                        )\n",
    "\n",
    "train_size = int(0.8*len(data))\n",
    "test_size = len(data)-train_size\n",
    "\n",
    "train_data, test_data = random_split(data,[train_size,test_size])\n",
    "\n",
    "train_loader = DataLoader(train_data,\n",
    "                    batch_size=4,\n",
    "                    shuffle=True,\n",
    "                    num_workers=4,\n",
    "                    pin_memory=True)\n",
    "\n",
    "test_loader = DataLoader(test_data,\n",
    "                    batch_size=1,\n",
    "                    shuffle=True,\n",
    "                    num_workers=4,\n",
    "                    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display one sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = data[int(torch.rand(1).item()*len(data))]\n",
    "\n",
    "rgb = sample[\"rgb\"]\n",
    "depth = sample[\"depth\"]\n",
    "depth_t = sample[\"depth_t\"]\n",
    "f, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(20,5))\n",
    "\n",
    "\n",
    "ax1.imshow(rgb.permute(1,2,0))\n",
    "ax2.imshow(depth.squeeze(0),cmap=\"gray\")\n",
    "ax3.imshow(depth_t.squeeze(0),cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "import model\n",
    "\n",
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "net = model.Net2().to(device)\n",
    "\n",
    "optimizer = optim.Adam(net.parameters(),lr=10**-3)\n",
    "\n",
    "# scheduler = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.train(model=net,\n",
    "            n_epochs = 30,\n",
    "            loss_fn = utils.rmse,\n",
    "            optimizer= optimizer,\n",
    "            device = device,\n",
    "            loader = train_loader,\n",
    "            log=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = next(iter(train_loader))\n",
    "rgb = sample[\"rgb\"].to(device)\n",
    "depth = sample[\"depth\"].to(device)\n",
    "depth_t = sample[\"depth_t\"].to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    net.eval()\n",
    "    out = net(rgb,depth_t).squeeze(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(20,10))\n",
    "\n",
    "ax1.imshow(rgb[0,...].permute(1,2,0).cpu())\n",
    "ax2.imshow(depth_t[0,...].squeeze().cpu(),cmap=\"gray\")\n",
    "ax3.imshow(depth[0,...].squeeze().cpu(),cmap=\"gray\")\n",
    "ax4.imshow(out.detach()[0,...].squeeze().cpu(),cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.load_state_dict(torch.load('weights/big_net_100.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 0\n",
    "d_acc = 0\n",
    "net.eval()\n",
    "for batch in test_loader:\n",
    "    rgb = batch[\"rgb\"].to(device)\n",
    "    depth = batch[\"depth\"].to(device)\n",
    "    depth_t = batch[\"depth_t\"].to(device)\n",
    "    n += 1\n",
    "    d_acc = ((n-1)*d_acc + utils.d_accuracy(net(rgb,depth_t),depth) ) / n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "730cf9b349456fd150aa69f5a53c05307454fca32bda7eea7a960c4826252cc2"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 ('visiope')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
